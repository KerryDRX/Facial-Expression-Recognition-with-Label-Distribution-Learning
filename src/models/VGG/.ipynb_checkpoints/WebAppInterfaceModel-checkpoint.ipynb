{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f73129",
   "metadata": {
    "id": "f9c5f7ae",
    "outputId": "ef5343f0-3fa3-430f-f344-0018236ebd36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35393, 48, 48, 1)\n",
      "(35393, 8)\n",
      "(35393, 8)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation test: rotate different degree (pay attention to adjustable filename etc.)\n",
    "import gradio as gr\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import layers, Sequential,losses, metrics\n",
    "\n",
    "image_height = 48\n",
    "image_width = 48\n",
    "emotions_count = 8\n",
    "emotion_labels = ['neutral', 'happiness', 'surprise', 'sadness',\n",
    "                  'anger', 'disgust', 'fear', 'contempt']\n",
    "\n",
    "# !!! change sample size\n",
    "samples = 130967 # 2~130968\n",
    "training_samples = 28317*4  # 2~113269 (Training)\n",
    "validation_samples = 3541*4 # 113270~127433 (PublicTest)\n",
    "test_samples = 3535         # 127434~130968 (PrivateTest)\n",
    "\n",
    "# !!! change npy folder name\n",
    "image_path = \"./dataset/images.npy\"\n",
    "emotion_multi_path = \"./dataset/emotions_multi.npy\"\n",
    "emotion_single_path = \"./dataset/emotions_single.npy\"\n",
    "images = np.load(image_path)\n",
    "emotions_multi = np.load(emotion_multi_path)\n",
    "emotions_single = np.load(emotion_single_path)\n",
    "\n",
    "# !!! change s/m dataset\n",
    "#emotions = emotions_single\n",
    "emotions = emotions_multi\n",
    "\n",
    "print(images.shape)\n",
    "print(emotions_multi.shape)\n",
    "print(emotions_single.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b42771",
   "metadata": {
    "id": "48b74ddb"
   },
   "outputs": [],
   "source": [
    "cce = losses.CategoricalCrossentropy()\n",
    "mse = losses.MeanSquaredError()\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "def model_acc(y_true, y_pred):\n",
    "    size = y_true.shape[0]\n",
    "    acc = 0\n",
    "    for i in range(size):\n",
    "        true = y_true[i]\n",
    "        pred = y_pred[i]           \n",
    "        index_max = tf.argmax(pred).numpy()\n",
    "        if true[index_max].numpy()==tf.reduce_max(true).numpy():\n",
    "            acc += 1\n",
    "    return acc/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40dd9ea",
   "metadata": {
    "id": "2e0551b8",
    "outputId": "abf956f1-48cb-4323-c907-b3a8e3addcd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_images shape: (35393, 48, 48, 1)\n",
      "training_emotions shape: (35393, 8)\n",
      "test_images shape: (0, 48, 48, 1)\n",
      "test_emotions shape: (0, 8)\n"
     ]
    }
   ],
   "source": [
    "images = tf.convert_to_tensor(images)\n",
    "\n",
    "emotions = tf.convert_to_tensor(emotions)\n",
    "\n",
    "images = layers.Rescaling(1./127.5, offset= -1)(images)\n",
    "\n",
    "training_size = training_samples + validation_samples\n",
    "test_size = test_samples\n",
    "\n",
    "training_images = images[:training_size]\n",
    "test_images = images[training_size:]\n",
    "training_emotions = emotions[:training_size]\n",
    "test_emotions = emotions[training_size:]\n",
    "\n",
    "print(\"training_images shape:\", training_images.shape)\n",
    "print(\"training_emotions shape:\", training_emotions.shape)\n",
    "print(\"test_images shape:\", test_images.shape)\n",
    "print(\"test_emotions shape:\", test_emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84729ccb",
   "metadata": {
    "id": "25c4fae6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import vgg16, resnet_v2\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.optimizer_v2 import adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582e8ba7",
   "metadata": {
    "id": "e1290bf0",
    "outputId": "24301af5-fad6-4240-c29c-69c8663f468d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1107/1107 [==============================] - 78s 67ms/step - loss: 0.0293 - model_acc: 0.6830\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 2/10\n",
      "1107/1107 [==============================] - 72s 65ms/step - loss: 0.0184 - model_acc: 0.7827\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 3/10\n",
      "1107/1107 [==============================] - 73s 66ms/step - loss: 0.0144 - model_acc: 0.8242\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 4/10\n",
      "1107/1107 [==============================] - 72s 65ms/step - loss: 0.0117 - model_acc: 0.8515\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 5/10\n",
      "1107/1107 [==============================] - 72s 65ms/step - loss: 0.0103 - model_acc: 0.8705\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 6/10\n",
      "1107/1107 [==============================] - 73s 66ms/step - loss: 0.0081 - model_acc: 0.8964\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 7/10\n",
      "1107/1107 [==============================] - 73s 66ms/step - loss: 0.0069 - model_acc: 0.9110\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 8/10\n",
      "1107/1107 [==============================] - 71s 64ms/step - loss: 0.0060 - model_acc: 0.9229\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 9/10\n",
      "1107/1107 [==============================] - 74s 67ms/step - loss: 0.0052 - model_acc: 0.9339\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n",
      "Epoch 10/10\n",
      "1107/1107 [==============================] - 72s 65ms/step - loss: 0.0047 - model_acc: 0.9368\n",
      "WARNING:tensorflow:Can save best model only with val_model_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    base_model = vgg16.VGG16(include_top=False, \n",
    "                             weights=\"imagenet\", \n",
    "                             input_shape=(48,48,3))\n",
    "    base_model.trainable=True\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dense(4096, activation='relu'),\n",
    "        layers.Dense(emotions_count, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=adam.Adam(learning_rate=1e-4), \n",
    "                  loss=mse, \n",
    "                  metrics = [model_acc])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "checkpoint_filepath = \"best_models/FERPlus_flip_+-25_multi_mse/model.ckpt\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_model_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "hist = model.fit(x=tf.image.grayscale_to_rgb(training_images),\n",
    "          y=training_emotions,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(tf.image.grayscale_to_rgb(test_images), test_emotions),\n",
    "          callbacks=[model_checkpoint_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61068a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    img_4d=img.reshape(-1,48,48,3)\n",
    "    prediction=best_model.predict(img_4d)[0]\n",
    "    return {class_names[i]: float(prediction[i]) for i in range(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9493f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25f87d76eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 269, in predict\n",
      "    output = await run_in_threadpool(app.launchable.process_api, body, username)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\concurrency.py\", line 39, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 573, in process_api\n",
      "    prediction, durations = self.process(raw_input)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 615, in process\n",
      "    predictions, durations = self.run_prediction(\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 531, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"C:\\Users\\Darkl\\AppData\\Local\\Temp/ipykernel_4720/2963500858.py\", line 3, in predict_image\n",
      "    prediction=best_model.predict(img_4d)[0]\n",
      "NameError: name 'best_model' is not defined\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 366, in run_asgi\n",
      "    result = await app(self.scope, self.receive, self.send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 75, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\", line 261, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 181, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 159, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 92, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 147, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\exceptions.py\", line 82, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\exceptions.py\", line 71, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 21, in __call__\n",
      "    raise e\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 656, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 259, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 61, in app\n",
      "    response = await func(request)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 227, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 160, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 304, in interpret\n",
      "    interpretation_scores, alternative_outputs = await run_in_threadpool(\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\starlette\\concurrency.py\", line 39, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 638, in interpret\n",
      "    return interpretation.run_interpret(self, raw_input)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\interpretation.py\", line 21, in run_interpret\n",
      "    original_output = interface.run_prediction(processed_input)\n",
      "  File \"C:\\Users\\Darkl\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 531, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"C:\\Users\\Darkl\\AppData\\Local\\Temp/ipykernel_4720/2963500858.py\", line 3, in predict_image\n",
      "    prediction=best_model.predict(img_4d)[0]\n",
      "NameError: name 'best_model' is not defined\n"
     ]
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(48,48))\n",
    "label = gr.outputs.Label(num_top_classes=5)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "BESTmodel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
